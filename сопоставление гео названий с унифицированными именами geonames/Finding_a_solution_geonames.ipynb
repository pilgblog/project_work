{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f39fa16",
   "metadata": {},
   "source": [
    "### Тестирование моделей, поиск решения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547080d8",
   "metadata": {},
   "source": [
    "### Пункт по поиску решений содержит следующий план рассмотрения моделей:\n",
    "- Расстояние Левенштейна\n",
    "- TF-IDF и косинусное подобие\n",
    "- Манхэттенское расстояние\n",
    "- Евклидово расстояние\n",
    "- Перевод и векторизация\n",
    "- Мультиязычная модель\n",
    "- Поиск сходства по Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09117dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: Levenshtein in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (0.23.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (from Levenshtein) (3.5.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78362db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\user\\appdata\\roaming\\python\\python39\\site-packages (1.7.4)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4661fab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from translate import Translator\n",
    "import logging\n",
    "from fuzzywuzzy import fuzz\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610d35d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c62aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим небольшой тестовый набор на русском и английском языках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "803944ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'Tambov'\n",
    "\n",
    "name_ru = ['Томбов', 'Тамбов', 'Tомбофф']\n",
    "name_en = ['tambopeu', 'Tombovf', 'Tambo']\n",
    "corpus = name_ru + name_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d9049",
   "metadata": {},
   "source": [
    "### Расстояние Левенштейна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "527f196c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сходство Левенштейна с русским текстом: [0, 0, 15]\n",
      "Сходство Левенштейна с английским текстом: [57, 77, 91]\n"
     ]
    }
   ],
   "source": [
    "def calculate_levenshtein_similarity(query, words):\n",
    "    similarities = []\n",
    "    for word in words:\n",
    "        comparison = fuzz.ratio(word, query)\n",
    "        similarities.append(round(comparison, 2))\n",
    "    return similarities\n",
    "\n",
    "levenshtein_similarity_ru = calculate_levenshtein_similarity(query, name_ru)\n",
    "print(f'Сходство Левенштейна с русским текстом: {levenshtein_similarity_ru}')\n",
    "\n",
    "levenshtein_similarity_en = calculate_levenshtein_similarity(query, name_en)\n",
    "print(f'Сходство Левенштейна с английским текстом: {levenshtein_similarity_en}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b17ad07",
   "metadata": {},
   "source": [
    "По результатам найденного нормальзованного неразрывного сходства расстояния Левенштейна, необходимо сделать предварительный перевод текста. Данная модель справилась лучше с английским текстом Tambo, которое явлется коротким и самым подходящим запросу. Следовательно можно сделать вывод, что модель справляется больше с сходством по длине слова."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42abceb6",
   "metadata": {},
   "source": [
    "### TF-IDF и косинусное подобие"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96aec0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сходство с русскими текстом: [1, 1, 1]\n",
      "Сходство с английским текстом: [0.47, 0.44, 0.79]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python39\\site-packages\\scipy\\spatial\\distance.py:622: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "# создадим функцию для векторизации с n-граммами\n",
    "def calculate_similarity(query, names, language='en', ngram_range=(2, 3)):\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=ngram_range)\n",
    "    tfidf_matrix = vectorizer.fit_transform(names)\n",
    "    vector_query = vectorizer.transform([query]).toarray()[0]\n",
    "\n",
    "    # Циклом вычислим косинусное сходство между запросом и списком\n",
    "    similarities = []\n",
    "    for name in names:\n",
    "        vector_name = vectorizer.transform([name]).toarray()[0]\n",
    "        cosine_similarity = 1 - distance.cosine(vector_name, vector_query)\n",
    "        similarities.append(round(cosine_similarity, 2))\n",
    "\n",
    "    return similarities\n",
    "\n",
    "\n",
    "similarity_ru = calculate_similarity('Tambov', name_ru, language='ru')\n",
    "print(f'Сходство с русскими текстом: {similarity_ru}')\n",
    "\n",
    "\n",
    "similarity_en = calculate_similarity('Tambov', name_en, language='en')\n",
    "print(f'Сходство с английским текстом: {similarity_en}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ed04b0",
   "metadata": {},
   "source": [
    "По результату мы видим, что необходимо переводить текст, так как с русским тектстом вектор не справился, по английскому тексту может фиксировать семантическое сходство."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65fdd92",
   "metadata": {},
   "source": [
    "### Манхэттенское расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dca6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Манхэттенское расстояние русского текста: [0.25, 0.25, 0.24]\n",
      "Манхэттенское расстояние английского текста: [0.23, 0.21, 0.41]\n"
     ]
    }
   ],
   "source": [
    "# напишем функцию для векторизации с n-граммами и метрикой манхэтэн\n",
    "def calculate_manhattan_similarity(query, names, metric='cosine', ngram_range=(2, 3)):\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=ngram_range)\n",
    "    tfidf_matrix = vectorizer.fit_transform(names)\n",
    "    vector_query = vectorizer.transform([query]).toarray()[0]\n",
    "    # добавим единицу чтобы при делении на ноль не получился ноль\n",
    "    distances_result = 1 / (1 + manhattan_distances([vector_query], tfidf_matrix)[0])\n",
    "    similarities = [round(similarity, 2) for similarity in distances_result]\n",
    "\n",
    "    return similarities\n",
    "    \n",
    "manhattan_similarity_ru = calculate_manhattan_similarity('Tambov', name_ru, metric='manhattan')\n",
    "print(f'Манхэттенское расстояние русского текста: {manhattan_similarity_ru}')\n",
    "\n",
    "manhattan_similarity_en = calculate_manhattan_similarity('Tambov', name_en, metric='manhattan')\n",
    "print(f'Манхэттенское расстояние английского текста: {manhattan_similarity_en}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb71f834",
   "metadata": {},
   "source": [
    "Манхэттенское расстояние более устойчиво для текста с опечатками, но судя по русскому тексту возможно оно плохо улавливает семантическое сходство."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953754fd",
   "metadata": {},
   "source": [
    "### Евклидово расстояние"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c49c9c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Евклидово расстояние русского текста: [0.5, 0.5, 0.5]\n",
      "Евклидово расстояние английского текста: [0.49, 0.49, 0.61]\n"
     ]
    }
   ],
   "source": [
    "# напишем функцию для векторизации с n-граммами и метрикой евклидово\n",
    "def calculate_euclidean_similarity(query, names, metric='cosine', ngram_range=(2, 3)):\n",
    "    vectorizer = TfidfVectorizer(analyzer=\"char\", ngram_range=ngram_range)\n",
    "    tfidf_matrix = vectorizer.fit_transform(names)\n",
    "    vector_query = vectorizer.transform([query]).toarray()[0]\n",
    "    distances_result = 1 / (1 + euclidean_distances([vector_query], tfidf_matrix)[0])\n",
    "    similarities = [round(similarity, 2) for similarity in distances_result]\n",
    "\n",
    "    return similarities\n",
    "    \n",
    "euclidean_similarity_ru = calculate_euclidean_similarity('Tambov', name_ru, metric='euclidean')\n",
    "print(f'Евклидово расстояние русского текста: {euclidean_similarity_ru}')\n",
    "\n",
    "euclidean_similarity_en = calculate_euclidean_similarity('Tambov', name_en, metric='euclidean')\n",
    "print(f'Евклидово расстояние английского текста: {euclidean_similarity_en}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f42b38",
   "metadata": {},
   "source": [
    "Евклидово расстояние показало практически одинаковые метрики английского и русского текста, так же мы видим что оно учитывает длину слова близкое к запросу. Работает хуже чем Манхэтенское расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2102975",
   "metadata": {},
   "source": [
    "Из всех вышеперчисленных моделей, лучший результат показало Манхэттенское расстояние."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e55b9",
   "metadata": {},
   "source": [
    "### Перевод и векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049a95e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toambov']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator = Translator(from_lang='ru', to_lang = 'en')\n",
    "tranlator_query = translator.translate('Тоамбовв').split()\n",
    "tranlator_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be44d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Манхэттенское расстояние текста c переводом: [0.36]\n"
     ]
    }
   ],
   "source": [
    "manhattan_similarity_query = calculate_manhattan_similarity('Tambov', tranlator_query, metric='manhattan')\n",
    "print(f'Манхэттенское расстояние текста c переводом: {manhattan_similarity_query}') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba8ce16",
   "metadata": {},
   "source": [
    "С помощью трансляции Манхэтенское рассстояние справляется, но хотелось бы лучше увидеть опечатки текста. Поэтому рассмотрим дальше мультиязычные модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb1c06b",
   "metadata": {},
   "source": [
    "### Мультиязычная модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67983e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fb066afd2c42aa86c945c252e8f8ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd633caba334f72b060796439425afc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Многоязычная модель версии: paraphrase-multilingual-mpnet-base-v2\n",
      "City: Tambo, Score: 0.95\n",
      "City: Тамбов, Score: 0.92\n",
      "City: tambopeu, Score: 0.89\n",
      "City: Томбов, Score: 0.6\n",
      "City: Tомбофф, Score: 0.57\n",
      "City: Tombovf, Score: 0.44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "329a66cd81d041719f476f2de3fbe239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8c9597f29cd4dd1a60d96af6e71bc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Многоязычная модель версии: distiluse-base-multilingual-cased-v2\n",
      "City: Тамбов, Score: 0.91\n",
      "City: Томбов, Score: 0.89\n",
      "City: Tambo, Score: 0.87\n",
      "City: Tомбофф, Score: 0.79\n",
      "City: Tombovf, Score: 0.78\n",
      "City: tambopeu, Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# напишем функции для двух версий многоязычной модели семантического сходства, версии которых поддерживают 50 языков\n",
    "def similarity_model(query, names, model, model_name):\n",
    "    embeddings = model.encode(names)\n",
    "    query_embedding = model.encode(query)\n",
    "\n",
    "    results = util.semantic_search(query_embedding, embeddings)[0]\n",
    "\n",
    "    print(f'Многоязычная модель версии: {model_name}', sep='\\n')\n",
    "    for result in results:\n",
    "        idx = int(result['corpus_id'])\n",
    "        score = result['score']\n",
    "        print(f'City: {names[idx]}, Score: {round(score, 2)}')\n",
    "\n",
    "model_par = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "similarity_model(query, corpus, model_par, 'paraphrase-multilingual-mpnet-base-v2')\n",
    "\n",
    "model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "similarity_model(query, corpus, model, 'distiluse-base-multilingual-cased-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5757f993",
   "metadata": {},
   "source": [
    "Многоязычная модель версии  универсального кодировщика предложений с расширенными знаниями показал результат лучше, чем многоязычная версия обученная на параллельных данных. Скор города Тамбов на первом месте второй модели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb39177",
   "metadata": {},
   "source": [
    "### Поиск сходства по Faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41a70d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4201efece0a643ff80832c3028ef4dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0720eab503e94ae7a2242e0ac510ca9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат по FAISS:\n",
      "City: Tambo, Distance: 0.83\n",
      "City: Тамбов, Distance: 1.37\n",
      "City: tambopeu, Distance: 1.46\n",
      "City: Томбов, Distance: 4.47\n",
      "City: Tомбофф, Distance: 4.76\n",
      "City: Tombovf, Distance: 5.98\n"
     ]
    }
   ],
   "source": [
    "# напишем функцию для использования faiss с евклидовой метрикой расстояния L2\n",
    "def faiss_similarity_search(query_embedding, embeddings):\n",
    "    # Преобразуем  данные во float32 для faiss\n",
    "    embeddings = np.array(embeddings, dtype=np.float32)\n",
    "    query_embedding = np.array(query_embedding, dtype=np.float32)\n",
    "\n",
    "    # Создадим экземпляр индекса\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "\n",
    "    # Выполним поиск по сходству\n",
    "    k = len(embeddings)\n",
    "    distances, indices = index.search(np.expand_dims(query_embedding, axis=0), k)\n",
    "\n",
    "    # Преобразуем все в список\n",
    "    indices = indices.flatten().tolist()\n",
    "    distances = distances.flatten().tolist()\n",
    "\n",
    "    return indices, distances\n",
    "\n",
    "# Используем многоязычную модель\n",
    "model = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "embeddings = model.encode(corpus)\n",
    "query_embedding = model.encode(query)\n",
    "# выполним сходство по faiss\n",
    "indices, distances = faiss_similarity_search(query_embedding, embeddings) \n",
    "print('Результат по FAISS:', sep='\\n')\n",
    "for idx, dist in zip(indices, distances):\n",
    "    print(f'City: {corpus[idx]}, Distance: {round(dist, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac9a11e",
   "metadata": {},
   "source": [
    "При испоьзовании Faiss мы видим что название города без опечаток стоит на втором месте. Результаты не плохие, но лучше работает мультиязычная модель версии distiluse-base-multilingual-cased-v2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
